{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorrt as trt\n",
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from PIL import ImageDraw\n",
    "\n",
    "from yolov3_to_onnx import download_file\n",
    "from data_processing import PreprocessYOLO, PostprocessYOLO, ALL_CATEGORIES\n",
    "\n",
    "import sys, os\n",
    "sys.path.insert(1, os.path.join(sys.path[0], \"..\"))\n",
    "import common\n",
    "\n",
    "TRT_LOGGER = trt.Logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will download the yolo v3 and convert to onnx\n",
    "!python yolov3_to_onnx.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# large model\n",
    "IMG_SIZE = 608\n",
    "\n",
    "# medium model\n",
    "# IMG_SIZE = 416"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_engine(onnx_file_path, engine_file_path=\"\"):\n",
    "    \"\"\"Attempts to load a serialized engine if available, otherwise builds a new TensorRT engine and saves it.\"\"\"\n",
    "    def build_engine():\n",
    "        \"\"\"Takes an ONNX file and creates a TensorRT engine to run inference with\"\"\"\n",
    "        with trt.Builder(TRT_LOGGER) as builder, builder.create_network(common.EXPLICIT_BATCH) as network, trt.OnnxParser(network, TRT_LOGGER) as parser:\n",
    "            builder.max_workspace_size = 1 << 28 # 256MiB\n",
    "            builder.max_batch_size = 1\n",
    "            # Parse model file\n",
    "            if not os.path.exists(onnx_file_path):\n",
    "                print('ONNX file {} not found, please run yolov3_to_onnx.py first to generate it.'.format(onnx_file_path))\n",
    "                exit(0)\n",
    "            print('Loading ONNX file from path {}...'.format(onnx_file_path))\n",
    "            with open(onnx_file_path, 'rb') as model:\n",
    "                print('Beginning ONNX file parsing')\n",
    "                if not parser.parse(model.read()):\n",
    "                    print ('ERROR: Failed to parse the ONNX file.')\n",
    "                    for error in range(parser.num_errors):\n",
    "                        print (parser.get_error(error))\n",
    "                    return None\n",
    "            # The actual yolov3.onnx is generated with batch size 64. Reshape input to batch size 1\n",
    "            network.get_input(0).shape = [1, 3, IMG_SIZE, IMG_SIZE]\n",
    "            print('Completed parsing of ONNX file')\n",
    "            print('Building an engine from file {}; this may take a while...'.format(onnx_file_path))\n",
    "            engine = builder.build_cuda_engine(network)\n",
    "            print(\"Completed creating Engine\")\n",
    "            with open(engine_file_path, \"wb\") as f:\n",
    "                f.write(engine.serialize())\n",
    "            return engine\n",
    "\n",
    "    if os.path.exists(engine_file_path):\n",
    "        # If a serialized engine exists, use it instead of building an engine.\n",
    "        print(\"Reading engine from file {}\".format(engine_file_path))\n",
    "        with open(engine_file_path, \"rb\") as f, trt.Runtime(TRT_LOGGER) as runtime:\n",
    "            return runtime.deserialize_cuda_engine(f.read())\n",
    "    else:\n",
    "        return build_engine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_bboxes(image_raw, bboxes, confidences, categories, all_categories, bbox_color='blue'):\n",
    "    \"\"\"Draw the bounding boxes on the original input image and return it.\n",
    "\n",
    "    Keyword arguments:\n",
    "    image_raw -- a raw PIL Image\n",
    "    bboxes -- NumPy array containing the bounding box coordinates of N objects, with shape (N,4).\n",
    "    categories -- NumPy array containing the corresponding category for each object,\n",
    "    with shape (N,)\n",
    "    confidences -- NumPy array containing the corresponding confidence for each object,\n",
    "    with shape (N,)\n",
    "    all_categories -- a list of all categories in the correct ordered (required for looking up\n",
    "    the category name)\n",
    "    bbox_color -- an optional string specifying the color of the bounding boxes (default: 'blue')\n",
    "    \"\"\"\n",
    "    draw = ImageDraw.Draw(image_raw)\n",
    "    print(bboxes, confidences, categories)\n",
    "    for box, score, category in zip(bboxes, confidences, categories):\n",
    "        x_coord, y_coord, width, height = box\n",
    "        left = max(0, np.floor(x_coord + 0.5).astype(int))\n",
    "        top = max(0, np.floor(y_coord + 0.5).astype(int))\n",
    "        right = min(image_raw.width, np.floor(x_coord + width + 0.5).astype(int))\n",
    "        bottom = min(image_raw.height, np.floor(y_coord + height + 0.5).astype(int))\n",
    "\n",
    "        draw.rectangle(((left, top), (right, bottom)), outline=bbox_color)\n",
    "        draw.text((left, top - 12), '{0} {1:.2f}'.format(all_categories[category], score), fill=bbox_color)\n",
    "\n",
    "    return image_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for faces\n",
    "IMAGE_PATH = 'warriors.jpg'\n",
    "!wget 'https://cdn.vox-cdn.com/thumbor/rC0mlBATZdoDW1tEa44P6431sGc=/0x0:3683x2455/1200x800/filters:focal(1623x234:2211x822)/cdn.vox-cdn.com/uploads/chorus_image/image/63273148/usa_today_12005182.0.jpg' -O {IMAGE_PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo 608\n",
    "onnx_file_path = \"yolov3.onnx\"\n",
    "engine_file_path = \"yolov3.trt\"\n",
    "\n",
    "# yolo 416\n",
    "# onnx_file_path = \"yolov3-face.onnx\"\n",
    "# engine_file_path = \"yolov3-face.trt\"\n",
    "# onnx_file_path = \"yolov3-416.onnx\"\n",
    "# engine_file_path = \"yolov3-416.trt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_resolution_yolov3_HW = (IMG_SIZE, IMG_SIZE)\n",
    "input_image_path = \"dog.jpg\"\n",
    "# input_image_path = IMAGE_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pre-processor object by specifying the required input resolution for YOLOv3\n",
    "preprocessor = PreprocessYOLO(input_resolution_yolov3_HW)\n",
    "# Load an image from the specified input path, and return it together with  a pre-processed version\n",
    "image_raw, image = preprocessor.process(input_image_path)\n",
    "# Store the shape of the original input image in WH format, we will need it for later\n",
    "shape_orig_WH = image_raw.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_outputs = []\n",
    "with get_engine(onnx_file_path, engine_file_path) as engine, engine.create_execution_context() as context:\n",
    "        inputs, outputs, bindings, stream = common.allocate_buffers(engine)\n",
    "        # Do inference\n",
    "        print('Running inference on image {}...'.format(input_image_path))\n",
    "        # Set host input to the image. The common.do_inference function will copy the input to the GPU before executing.\n",
    "        inputs[0].host = image\n",
    "        trt_outputs = common.do_inference_v2(context, bindings=bindings, inputs=inputs, outputs=outputs, stream=stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coco\n",
    "NUM_OUTPUTS = 255\n",
    "\n",
    "# faces\n",
    "# NUM_OUTPUTS = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_outputs[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 43095 / 13/13\n",
    "# 3042 / 13 / 13\n",
    "# 92055 / 255 / 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_outputs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trt_outputs[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 416 layers / dims\n",
    "# output_tensor_dims['082_convolutional'] = [255, 13, 13]\n",
    "# output_tensor_dims['094_convolutional'] = [255, 26, 26]\n",
    "# output_tensor_dims['106_convolutional'] = [255, 52, 52]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 608 shapes\n",
    "# output_shapes = [(1, 255, 19, 19), (1, 255, 38, 38), (1, 255, 76, 76)]\n",
    "# 416 shapes\n",
    "output_shapes = [(1, NUM_OUTPUTS, 13, 13), (1, NUM_OUTPUTS, 26, 26), (1, NUM_OUTPUTS, 52, 52)]\n",
    "\n",
    "\n",
    "trt_outputs = [output.reshape(shape) for output, shape in zip(trt_outputs, output_shapes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessor_args = {\"yolo_masks\": [(6, 7, 8), (3, 4, 5), (0, 1, 2)],                    # A list of 3 three-dimensional tuples for the YOLO masks\n",
    "                          \"yolo_anchors\": [(10, 13), (16, 30), (33, 23), (30, 61), (62, 45),  # A list of 9 two-dimensional tuples for the YOLO anchors\n",
    "                                           (59, 119), (116, 90), (156, 198), (373, 326)],\n",
    "                          \"obj_threshold\": 0.6,                                               # Threshold for object coverage, float value between 0 and 1\n",
    "                          \"nms_threshold\": 0.5,                                               # Threshold for non-max suppression algorithm, float value between 0 and 1\n",
    "                          \"yolo_input_resolution\": input_resolution_yolov3_HW}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postprocessor = PostprocessYOLO(**postprocessor_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the post-processing algorithms on the TensorRT outputs and get the bounding box details of detected objects\n",
    "boxes, classes, scores = postprocessor.process(trt_outputs, (shape_orig_WH))\n",
    "# Draw the bounding boxes onto the original input image and save it as a PNG file\n",
    "obj_detected_img = draw_bboxes(image_raw, boxes, scores, classes, ALL_CATEGORIES)\n",
    "output_image_path = 'dog_bboxes.png'\n",
    "obj_detected_img.save(output_image_path, 'PNG')\n",
    "print('Saved image with bounding boxes of detected objects to {}.'.format(output_image_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "Image(filename='dog_bboxes.png') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
